{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa625fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prakh\\Downloads\\RAG_legal\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- 1. SETUP ---\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "#JSON file - RAG Dataset\n",
    "file_path = \"IndicLegalQA Dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd984747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load the dataset ---\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    print(\"Please update the 'file_path' variable with the correct location of your dataset.\")\n",
    "    exit()\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode JSON from the file '{file_path}'.\")\n",
    "    print(\"Please ensure it is a valid JSON file.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc27ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Prepare documents ---\n",
    "# We format each item in the JSON file into a LangChain Document object.\n",
    "# This combines the structured data into a single text block for the RAG pipeline.\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=f\"Case: {item['case_name']}\\nDate: {item['judgement_date']}\\nQuestion: {item['question']}\\nAnswer: {item['answer']}\"\n",
    "    )\n",
    "    for item in data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb768a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Split documents into chunks ---\n",
    "# This breaks down the long documents into smaller pieces that are easier for the model to process.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e76c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings...\n",
      "Creating FAISS vector store... This might take a few minutes.\n",
      "Creating FAISS vector store... This might take a few minutes.\n",
      "Vector store created and saved successfully.\n",
      "Vector store created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Create embeddings and FAISS vector store ---\n",
    "# This converts the text chunks into numerical vectors (embeddings) and stores them\n",
    "# in a FAISS index for efficient similarity searching.\n",
    "print(\"Creating embeddings...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "if os.path.exists(\"faiss_index\"):\n",
    "    vector_store = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Loaded existing FAISS index.\")\n",
    "else:\n",
    "    print(\"Creating FAISS vector store... This might take a few minutes.\")\n",
    "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "    vector_store.save_local(\"faiss_index\")\n",
    "    print(\"Vector store created and saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f64f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Setup the RAG chain with Groq ---\n",
    "# Initialize the Groq LLM with your API key and the desired model.\n",
    "groq_llm = ChatGroq(groq_api_key=api_key, model_name=\"openai/gpt-oss-120b\")\n",
    "\n",
    "# Create a retriever from our vector store to fetch relevant documents.\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Define the prompt template to guide the LLM's responses.\n",
    "prompt_template = \"\"\"\n",
    "You are a legal expert on Indian law. Use the following context to answer the question.\n",
    "If you don't know the answer, just say you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Create the RetrievalQA chain, which combines the retriever and the LLM.\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=groq_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb9e93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying the RAG system with: 'What was the final decision of the Armed Forces Tribunal in the case Union of India vs. Maj. Gen. Manomoy Ganguly?'\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Query the RAG system ---\n",
    "# Define the question you want to ask.\n",
    "question = \"What was the final decision of the Armed Forces Tribunal in the case Union of India vs. Maj. Gen. Manomoy Ganguly?\"\n",
    "\n",
    "# Invoke the chain to get the answer.\n",
    "print(f\"\\nQuerying the RAG system with: '{question}'\")\n",
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c303fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question ---\n",
      "What was the final decision of the Armed Forces Tribunal in the case Union of India vs. Maj. Gen. Manomoy Ganguly?\n",
      "\n",
      "--- Answer ---\n",
      "The Armed Forces Tribunal (AFT) directed that Maj. Gen. Manomoy Ganguly be posted as Director General Medical Services (Army) **as expeditiously as possible, and within one month of the date of its judgment**.\n",
      "\n",
      "--- Source Documents Used ---\n",
      "Source 1:\n",
      "Case: Union of India vs. Maj. Gen. Manomoy Ganguly\n",
      "Date: 1st August 2018\n",
      "Question: What decision did the Armed Forces Tribunal (AFT) make regarding Maj. Gen. Manomoy Ganguly's promotion?\n",
      "Answer: The AFT directed the appellants to post Maj. Gen. Manomoy Ganguly as DGMS (Army) as expeditiously as possible and within one month from the date of the judgement.\n",
      "---------------------------------\n",
      "Source 2:\n",
      "Case: Union of India vs. Maj. Gen. Manomoy Ganguly\n",
      "Date: 1st August 2018\n",
      "Question: What was the main issue in the case Union of India vs. Maj. Gen. Manomoy Ganguly?\n",
      "Answer: The main issue was Maj. Gen. Manomoy Ganguly's denial of promotion to the position of Director General Medical Services (Army) despite being eligible and senior.\n",
      "---------------------------------\n",
      "Source 3:\n",
      "Case: Union of India vs. Maj. Gen. Manomoy Ganguly\n",
      "Date: 1st August 2018\n",
      "Question: What were the final instructions of the Supreme Court regarding the promotion of Maj. Gen. Manomoy Ganguly?\n",
      "Answer: The Supreme Court instructed that Maj. Gen. Manomoy Ganguly should be appointed to the post of DGMS (Army) without further delay, in accordance with the AFT's decision.\n",
      "---------------------------------\n",
      "Source 4:\n",
      "Case: Union of India vs. Maj. Gen. Manomoy Ganguly\n",
      "Date: 1st August 2018\n",
      "Question: Who is the respondent in the case Union of India vs. Maj. Gen. Manomoy Ganguly?\n",
      "Answer: The respondent is Maj. Gen. Manomoy Ganguly.\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Print the results ---\n",
    "print(\"\\n--- Question ---\")\n",
    "print(question)\n",
    "\n",
    "print(\"\\n--- Answer ---\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"\\n--- Source Documents Used ---\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"Source {i+1}:\\n{doc.page_content}\")\n",
    "    print(\"---------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
